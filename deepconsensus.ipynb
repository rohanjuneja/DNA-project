{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanjuneja/DNA-project/blob/main/deepconsensus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQAwmtN43ooK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils import data as D\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnTJBfXZ3ooO"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyz3qCqR3ooP"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkpC4qZq3ooR"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class DeepConsensus(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt)\n",
        "        out = self.out(transformer_out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TUIgcil3ooS",
        "outputId": "c1874a31-7388-46d4-e962-25146d8e4ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one-hot encoding for DNA bases\n",
            "A: [[1, 0, 0, 0, 0]]\n",
            "C: [[0, 1, 0, 0, 0]]\n",
            "G: [[0, 0, 1, 0, 0]]\n",
            "T: [[0, 0, 0, 1, 0]]\n"
          ]
        }
      ],
      "source": [
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "bmap = {\"A\":0, \"C\":1, \"G\":2, \"T\":3, \"$\":4}\n",
        "def one_hot(b):\n",
        "    t = [[0,0,0,0,0]]\n",
        "    i = bmap[b]\n",
        "    t[0][i] = 1\n",
        "    return t\n",
        "\n",
        "print(\"one-hot encoding for DNA bases\")\n",
        "print(\"A:\", one_hot(\"A\"))\n",
        "print(\"C:\", one_hot(\"C\"))\n",
        "print(\"G:\", one_hot(\"G\"))\n",
        "print(\"T:\", one_hot(\"T\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xupmqCjm3ooT"
      },
      "outputs": [],
      "source": [
        "# Introducing the error in DNA sequence\n",
        "\n",
        "def sim_error(seq, pi=0.05, pd=0.05, ps=0.01):\n",
        "    \"\"\"\n",
        "    Given an input sequence `seq`, generating another\n",
        "    sequence with errors. \n",
        "    pi: insertion error rate\n",
        "    pd: deletion error rate\n",
        "    ps: substitution error rate\n",
        "    \"\"\"\n",
        "    out_seq = []\n",
        "    for c in seq:\n",
        "        while 1:\n",
        "            r = random.uniform(0,1)\n",
        "            if r < pi:\n",
        "                out_seq.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "            else:\n",
        "                break\n",
        "        r -= pi\n",
        "        if r < pd:\n",
        "            continue\n",
        "        r -= pd\n",
        "        if r < ps:\n",
        "            out_seq.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "            continue\n",
        "        out_seq.append(c)\n",
        "    return \"\".join(out_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MqB2n763ooU",
        "outputId": "b31ea7db-00c1-4a73-b731-872922d1db45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CGTTTAACTACGAGCCGGTAGATCCACTTTTTTTATGAAGATCTTTCGCGTAGCGGAGCATAGCTACATCATACGAAGTCCGGCAGTCCCTAAAATGGGGTGGGATTGCGTTAATTAGCT\n"
          ]
        }
      ],
      "source": [
        "seq = [random.choice([\"A\",\"C\",\"G\",\"T\"]) for _ in range(120)]\n",
        "print(\"\".join(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8krt_iG3ooV",
        "outputId": "d7c99ab4-31af-4788-88cb-87e5ffb4ea8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([120])\n"
          ]
        }
      ],
      "source": [
        "seq_vec = torch.FloatTensor([bmap[c] for c in seq])\n",
        "print(seq_vec.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "einKqBne3ooV",
        "outputId": "119ed37d-ca10-4240-a159-0886270a6f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1., device='cpu')\n"
          ]
        }
      ],
      "source": [
        "print(seq_vec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ4JsYAM3ooW"
      },
      "source": [
        "### Generate Training data and Train the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPhv8Ilm3ooX",
        "outputId": "24e9e3b5-b6e4-4c20-ffc2-06668735b9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATCGCACATAAGTGAATGCGGACCTGTTCCTCGTTGTGTACTTTATCGCAAAAGGTCGATATTTTCGACCACCGTCAGATTAGCACGTCACTTGCAGCTATTTTCTCTTTAAATACACGC\n",
            "10000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "num_clusters = 10000\n",
        "train_consensus_strands = []\n",
        "train_target = []\n",
        "for i in range(num_clusters):\n",
        "    strand = [random.choice([\"A\",\"C\",\"G\",\"T\"]) for _ in range(120)]\n",
        "    train_consensus_strands.append(strand)\n",
        "    strand_t = [bmap[c] for c in strand]\n",
        "#     strand_t = Variable(torch.FloatTensor([one_hot(c) for c in strand]))\n",
        "    train_target.append(strand_t)\n",
        "print(\"\".join(strand))\n",
        "\n",
        "print(len(train_consensus_strands))\n",
        "print(len(train_target))\n",
        "\n",
        "train_target = torch.Tensor(train_target).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qVuvh5J3ooX",
        "outputId": "2629f938-a2cc-43c4-93e9-08f1c83efc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 120])\n"
          ]
        }
      ],
      "source": [
        "print(train_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IAnT-zH3ooY"
      },
      "outputs": [],
      "source": [
        "train_data = []\n",
        "\n",
        "for i in range(num_clusters):\n",
        "    train_clusters = []\n",
        "    seq = train_consensus_strands[i]\n",
        "    for j in range(10):\n",
        "        noisy_seq = sim_error(seq, pi=random.uniform(0.03, 0.09), pd=random.uniform(0.03, 0.09), \n",
        "        ps=random.uniform(0.03, 0.09))\n",
        "        noisy_seq_t = [bmap[c] for c in noisy_seq]\n",
        "#         noisy_seq_t = Variable(torch.FloatTensor([one_hot(c) for c in noisy_seq])).cuda()\n",
        "        train_clusters.append(noisy_seq_t)\n",
        "        \n",
        "    train_data.append(train_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nAc-SAV3ooY",
        "outputId": "a342afa1-a831-46d6-de47-6532e15fc95e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        if (len(train_data[i][j]) > max_length):\n",
        "            max_length = len(train_data[i][j])\n",
        "\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXEeSmFr3ooY",
        "outputId": "740c5ce3-69d8-4199-908b-a1b3513c57c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "min_length = 0\n",
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        if (i == 0 and j == 0):\n",
        "            min_length = len(train_data[i][j])\n",
        "            \n",
        "        elif (len(train_data[i][j]) < min_length):\n",
        "            min_length = len(train_data[i][j])\n",
        "\n",
        "print(min_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPqpy6yN3ooZ"
      },
      "outputs": [],
      "source": [
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        diff = max_length - len(train_data[i][j])\n",
        "        for k in range(diff):\n",
        "            train_data[i][j].append(int(4))\n",
        "\n",
        "train_data = torch.Tensor(train_data).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y97jkMxS3ooZ",
        "outputId": "8e209ace-9a86-4da4-a292-2c6609b8855f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 10, 143])\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryjjtpas3ooZ"
      },
      "outputs": [],
      "source": [
        "model = DeepConsensus(num_tokens=5, dim_model=120, num_heads=2, \n",
        "                      num_encoder_layers=6, num_decoder_layers=0, dropout_p=0.1)\n",
        "model.cuda()\n",
        "model.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgHMhFCM3ooZ"
      },
      "outputs": [],
      "source": [
        "initial_lr = 0.1\n",
        "lr=initial_lr\n",
        "optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIrbY3zj3ooa",
        "outputId": "18c33aee-1fa0-41c8-f68f-866c26eb97b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one-hot encoding for DNA bases\n",
            "A: [[1, 0, 0, 0, 0]]\n",
            "C: [[0, 1, 0, 0, 0]]\n",
            "G: [[0, 0, 1, 0, 0]]\n",
            "T: [[0, 0, 0, 1, 0]]\n",
            "$: [[0, 0, 0, 0, 1]]\n"
          ]
        }
      ],
      "source": [
        "def vec_to_one_hot(b):\n",
        "    t = [[0,0,0,0,0]]\n",
        "    i = b\n",
        "    t[0][i] = 1\n",
        "    return t\n",
        "\n",
        "print(\"one-hot encoding for DNA bases\")\n",
        "print(\"A:\", vec_to_one_hot(0))\n",
        "print(\"C:\", vec_to_one_hot(1))\n",
        "print(\"G:\", vec_to_one_hot(2))\n",
        "print(\"T:\", vec_to_one_hot(3))\n",
        "print(\"$:\", vec_to_one_hot(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mv6HpvI3ooa",
        "outputId": "09e409ba-3927-4a73-8228-d2a18beed7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 120, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "train_target_one_hot = []\n",
        "\n",
        "for i in range(int(len(train_target))):\n",
        "    train_target_one_hot.append([])\n",
        "    for j in range(int(len(train_target[i]))):\n",
        "        train_target_one_hot[i].append(vec_to_one_hot(int(train_target[i][j])))\n",
        "        \n",
        "train_target_one_hot = torch.Tensor(train_target_one_hot).long().cuda()\n",
        "print(train_target_one_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asWYR7TS3ooa",
        "outputId": "87e74b1c-a77f-4506-9b11-bfa5bfe8d08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training loss: 0.004787557220458984 learning rate: 0.1\n",
            "Epoch: 1 Training loss: 0.00478189811706543 learning rate: 0.095\n",
            "Epoch: 2 Training loss: 0.004785650253295899 learning rate: 0.095\n",
            "Epoch: 3 Training loss: 0.004775938034057617 learning rate: 0.09025\n",
            "Epoch: 4 Training loss: 0.004784066390991211 learning rate: 0.09025\n",
            "Epoch: 5 Training loss: 0.004779855728149414 learning rate: 0.0857375\n",
            "Epoch: 6 Training loss: 0.004784226989746094 learning rate: 0.0857375\n",
            "Epoch: 7 Training loss: 0.004781884765625 learning rate: 0.08145062499999998\n",
            "Epoch: 8 Training loss: 0.004780577850341797 learning rate: 0.08145062499999998\n",
            "Epoch: 9 Training loss: 0.004782878494262695 learning rate: 0.07737809374999999\n",
            "Epoch: 10 Training loss: 0.004785377502441407 learning rate: 0.07737809374999999\n",
            "Epoch: 11 Training loss: 0.0047844989776611325 learning rate: 0.07350918906249998\n",
            "Epoch: 12 Training loss: 0.0047859367370605465 learning rate: 0.07350918906249998\n",
            "Epoch: 13 Training loss: 0.0047820453643798826 learning rate: 0.06983372960937498\n",
            "Epoch: 14 Training loss: 0.004782716369628906 learning rate: 0.06983372960937498\n",
            "Epoch: 15 Training loss: 0.00477920036315918 learning rate: 0.06634204312890622\n",
            "Epoch: 16 Training loss: 0.004782327270507813 learning rate: 0.06634204312890622\n",
            "Epoch: 17 Training loss: 0.004783945846557617 learning rate: 0.0630249409724609\n",
            "Epoch: 18 Training loss: 0.004779141235351563 learning rate: 0.0630249409724609\n",
            "Epoch: 19 Training loss: 0.00478017578125 learning rate: 0.05987369392383786\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "num_epochs = 20\n",
        "\n",
        "range_ = (1, 120)\n",
        "# mini_batch_size = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(int(len(train_data))):\n",
        "        train_loss = 0\n",
        "        s, e = range_\n",
        "        optimizer.zero_grad()\n",
        "        count = 0\n",
        "        for seq in train_data[i]:\n",
        "            model.zero_grad()\n",
        "            count = count + 1\n",
        "            # Noisy clusters (training data)\n",
        "            seq = seq[s-1:e]\n",
        "            seq_ = seq.view(-1,120)\n",
        "            # Original string (training target)\n",
        "            seq_target = train_target[i][s-1:e]\n",
        "            seq_target = seq_target.view(-1, 120)\n",
        "            # Forward Prop\n",
        "            out = model(seq_, seq_target)\n",
        "            # Loss computation\n",
        "            train_loss += criterion(out, train_target_one_hot[i][count])\n",
        "            \n",
        "        # Backward propagation operation\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Epoch:\", epoch, \"Training loss:\", train_loss.cpu().item()/len(train_data), \"learning rate:\", lr)\n",
        "        \n",
        "    # Learning rate decay\n",
        "    if epoch % 2 ==0:\n",
        "        lr *= 0.95\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    \n",
        "if (num_epochs > 0):\n",
        "    torch.save(model.state_dict(), \"deepconsensus.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE5mjK3X3ooa",
        "outputId": "03eac035-62be-4a77-f482-58308b253c84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"deepconsensus.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D744OD0b3oob"
      },
      "source": [
        "### Generate Test Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIMayqbc3oob",
        "outputId": "a3c60551-667e-4351-933b-3ab80fd1bda8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATGCGCCCGCTAGATGGCATGGCAGTCTAAGAGGCCGCATAAGTACACAACTCGATCTGGTTACCGAACCGCCTTACCGCCTGCGAGTTACAGCTTTTTGCCGCATAGTCATCTCGCGGA\n",
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "# DNA clusters to test model\n",
        "num_test_clusters = 1000\n",
        "test_consensus_strands = []\n",
        "test_target = []\n",
        "\n",
        "for i in range(num_test_clusters):\n",
        "    strand = [random.choice([\"A\",\"C\",\"G\",\"T\"]) for _ in range(120)]\n",
        "    test_consensus_strands.append(strand)\n",
        "    strand_t = [bmap[c] for c in strand]\n",
        "    \n",
        "    test_target.append(strand_t)\n",
        "    \n",
        "print(\"\".join(strand))\n",
        "\n",
        "print(len(test_consensus_strands))\n",
        "print(len(test_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chA4NS8v3oob"
      },
      "outputs": [],
      "source": [
        "test_target = torch.Tensor(test_target).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7oCIdBS3oob"
      },
      "outputs": [],
      "source": [
        "test_data = []\n",
        "\n",
        "for i in range(num_test_clusters):\n",
        "    test_clusters = []\n",
        "    seq = test_consensus_strands[i]\n",
        "    for j in range(10):\n",
        "        noisy_seq = sim_error(seq, pi=0.06, pd=0.06, ps=0.06)\n",
        "        \n",
        "        noisy_seq_t = [bmap[c] for c in noisy_seq]\n",
        "        \n",
        "        test_clusters.append(noisy_seq_t)\n",
        "        \n",
        "    test_data.append(test_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBcz8N0L3oob",
        "outputId": "83ec2954-56c5-41aa-f5b4-1f2e538e2950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        if (len(test_data[i][j]) > max_length):\n",
        "            max_length = len(test_data[i][j])\n",
        "\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgA5aFvG3oob",
        "outputId": "4ed9f78c-f6c8-49ac-8ec0-b75dfc991f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105\n"
          ]
        }
      ],
      "source": [
        "min_length = 0\n",
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        if (i == 0 and j == 0):\n",
        "            min_length = len(test_data[i][j])\n",
        "            \n",
        "        elif (len(test_data[i][j]) < min_length):\n",
        "            min_length = len(test_data[i][j])\n",
        "\n",
        "print(min_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39AV5wKj3oob"
      },
      "outputs": [],
      "source": [
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        diff = max_length - len(test_data[i][j])\n",
        "        for k in range(diff):\n",
        "            test_data[i][j].append(int(4))\n",
        "\n",
        "test_data = torch.Tensor(test_data).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y69CmJS83oob",
        "outputId": "7b89d72a-c57c-4561-a226-ba78f13604b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 10, 138])\n"
          ]
        }
      ],
      "source": [
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6ttHGbr3ooc",
        "outputId": "bee232ca-a090-4b9f-ca61-578ba415472b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 120])\n"
          ]
        }
      ],
      "source": [
        "print(test_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDMdFcWO3ooc",
        "outputId": "b24c7885-61a0-4de8-e455-a37ef7bd3479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5])\n",
            "torch.float32\n",
            "Vectors for one hot of DNA bases\n",
            "A: 0\n",
            "C: 1\n",
            "G: 2\n",
            "T: 3\n",
            "$: 4\n"
          ]
        }
      ],
      "source": [
        "def one_hot_to_vec(one_hot):\n",
        "    one_hot = np.array(one_hot)\n",
        "    vec = np.argmax(one_hot, axis = 0)\n",
        "    return vec\n",
        "\n",
        "vec = torch.zeros(5).cpu()\n",
        "vec[0] = 1\n",
        "print(vec.shape)\n",
        "print(vec.dtype)\n",
        "\n",
        "print(\"Vectors for one hot of DNA bases\")\n",
        "print(\"A:\", one_hot_to_vec(vec))\n",
        "print(\"C:\", one_hot_to_vec([0, 1, 0, 0, 0]))\n",
        "print(\"G:\", one_hot_to_vec([0, 0, 1, 0, 0]))\n",
        "print(\"T:\", one_hot_to_vec([0, 0, 0, 1, 0]))\n",
        "print(\"$:\", one_hot_to_vec([0, 0, 0, 0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVS1sMTG3ooc",
        "outputId": "2d70169f-aa45-4936-9bfa-5d6e92603aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 120, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "test_target_one_hot = []\n",
        "\n",
        "for i in range(int(len(test_target))):\n",
        "    test_target_one_hot.append([])\n",
        "    for j in range(int(len(test_target[i]))):\n",
        "        test_target_one_hot[i].append(vec_to_one_hot(int(test_target[i][j])))\n",
        "        \n",
        "test_target_one_hot = torch.Tensor(test_target_one_hot).long().cuda()\n",
        "print(test_target_one_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYXhFdEn3ooc",
        "outputId": "3dfc2fd3-c054-4255-8271-5ce1aaa5aa1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for forward prop per DNA sequence = 0.006760358810424805 sec\n",
            "Time for accuracy calculation per DNA sequence = 0.006854057312011719 sec\n",
            "Accuracy = 0.75125\n"
          ]
        }
      ],
      "source": [
        "range_ = (1, 120)\n",
        "accuracy = 0\n",
        "\n",
        "model.eval()\n",
        "# Run again\n",
        "for i in range(len(test_data)):\n",
        "    test_loss = 0\n",
        "    s, e = range_\n",
        "    for seq in test_data[i]:\n",
        "        start_time = time.time()\n",
        "        model.zero_grad()\n",
        "        # Original string (test target)\n",
        "        seq_target = test_target[i][s-1:e]\n",
        "        seq_target = seq_target.view(-1, 120)\n",
        "        # Noisy clusters (test data)\n",
        "        seq = seq[s-1:e]\n",
        "        seq_ = seq.view(-1,120)\n",
        "        out = model(seq_, seq_target)\n",
        "        check_time = time.time()\n",
        "        \n",
        "        for j in range(120):\n",
        "            if (one_hot_to_vec(out[0][j].detach().cpu().numpy()) == \n",
        "                one_hot_to_vec(test_target_one_hot[i][j].reshape(5).detach().cpu().numpy())):\n",
        "                \n",
        "                accuracy = accuracy + 1\n",
        "                \n",
        "        end_time = time.time()\n",
        "        \n",
        "print(\"Time for forward prop per DNA sequence = \" + str(check_time - start_time) + \" sec\")\n",
        "print(\"Time for accuracy calculation per DNA sequence = \" + str(end_time - check_time) + \" sec\")\n",
        "                \n",
        "print(\"Accuracy = \" + str(accuracy/(test_data.shape[0] * test_data.shape[1] * 120)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exJ-919Z3ood"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "deepconsensus.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}