{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanjuneja/DNA-project/blob/main/deepconsensus_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIafg_sY3oo2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils import data as D\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYYsVcv33oo7"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsIYlxQm3oo8"
      },
      "source": [
        "### Define the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywc42IxW3oo9"
      },
      "outputs": [],
      "source": [
        "# Defining the positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGlTT4rZ3opA"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class DeepConsensus(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt)\n",
        "        out = self.out(transformer_out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAOLACm93opB",
        "outputId": "6db91038-ab41-4736-a5ea-7fd7e0ffe3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one-hot encoding for DNA bases\n",
            "A: [[1, 0, 0, 0, 0, 0, 0]]\n",
            "C: [[0, 1, 0, 0, 0, 0, 0]]\n",
            "G: [[0, 0, 1, 0, 0, 0, 0]]\n",
            "T: [[0, 0, 0, 1, 0, 0, 0]]\n",
            "$: [[0, 0, 0, 0, 1, 0, 0]]\n",
            "%: [[0, 0, 0, 0, 0, 1, 0]]\n",
            "#: [[0, 0, 0, 0, 0, 0, 1]]\n"
          ]
        }
      ],
      "source": [
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "bmap = {\"A\":0, \"C\":1, \"G\":2, \"T\":3, \"$\":4, \"%\":5, \"#\":6}\n",
        "def one_hot(b):\n",
        "    t = [[0,0,0,0,0,0,0]]\n",
        "    i = bmap[b]\n",
        "    t[0][i] = 1\n",
        "    return t\n",
        "\n",
        "print(\"one-hot encoding for DNA bases\")\n",
        "print(\"A:\", one_hot(\"A\"))\n",
        "print(\"C:\", one_hot(\"C\"))\n",
        "print(\"G:\", one_hot(\"G\"))\n",
        "print(\"T:\", one_hot(\"T\"))\n",
        "print(\"$:\", one_hot(\"$\"))\n",
        "print(\"%:\", one_hot(\"%\"))\n",
        "print(\"#:\", one_hot(\"#\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQl3zW2w3opE"
      },
      "outputs": [],
      "source": [
        "# Function to add noise within the data\n",
        "def sim_error(seq, pi=0.05, pd=0.05, ps=0.01):\n",
        "    \"\"\"\n",
        "    Given an input sequence `seq`, generating another\n",
        "    sequence with errors. \n",
        "    pi: insertion error rate\n",
        "    pd: deletion error rate\n",
        "    ps: substitution error rate\n",
        "    \"\"\"\n",
        "    out_seq = [\"%\"]\n",
        "    for c in seq:\n",
        "        if (c != \"#\" or c != \"%\"):\n",
        "            while (1):\n",
        "                r = random.uniform(0,1)\n",
        "                if r < pi:\n",
        "                    out_seq.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "                else:\n",
        "                    break\n",
        "            r -= pi\n",
        "            if r < pd:\n",
        "                continue\n",
        "            r -= pd\n",
        "            if r < ps:\n",
        "                out_seq.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "                continue\n",
        "        out_seq.append(c)\n",
        "    return \"\".join(out_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au01B2-B3opF",
        "outputId": "a49853d5-b9be-40a3-d0dc-14bb0a7930c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%TAATGCCTTCCCTCCGGTATCGCTCAGAGCATCCTGCGGGCGCTTCACGCCAGGTCGTCTACATGAAGTGTCGTCAAGCTTTACTACTCTCAGTGTCGGTGTGTGCTCGGACGAATCATG#\n"
          ]
        }
      ],
      "source": [
        "seq = [\"%\"]\n",
        "for _ in range(120):\n",
        "    seq.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "seq.append(\"#\")\n",
        "print(\"\".join(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWIGCQGj3opG",
        "outputId": "d8117244-cd9a-47c1-e675-267ec2180283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([122])\n"
          ]
        }
      ],
      "source": [
        "seq_vec = torch.FloatTensor([bmap[c] for c in seq])\n",
        "print(seq_vec.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zB_BM63opH",
        "outputId": "b7f39f20-e584-4ee6-bc6e-a7d7496126b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5., device='cpu')\n"
          ]
        }
      ],
      "source": [
        "print(seq_vec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQPmYRi53opI"
      },
      "source": [
        "### Generate training data and Perform Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd96GeZA3opI",
        "outputId": "24f0dc03-2fc2-4e8c-cbd1-ef6cffe9da60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%GCCTTAGTCGTAACCCTGAAGGAAGGTACTTACTGCTGGCATGGTGAAGGAACGAGCGCCCAGCACGCACGGTTCGGGGTCGGATGTCTTTGTTTCACGAACTTTTATAATGGAAAGTTG#\n",
            "10000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "# Generate training strings\n",
        "num_clusters = 10000\n",
        "train_consensus_strands = []\n",
        "train_target = []\n",
        "for i in range(num_clusters):\n",
        "    strand = [\"%\"]\n",
        "    for _ in range(120):\n",
        "        strand.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "    strand.append(\"#\")\n",
        "    \n",
        "    train_consensus_strands.append(strand)\n",
        "    strand_t = [bmap[c] for c in strand]\n",
        "    train_target.append(strand_t)\n",
        "print(\"\".join(strand))\n",
        "\n",
        "print(len(train_consensus_strands))\n",
        "print(len(train_target))\n",
        "\n",
        "train_target = torch.Tensor(train_target).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76uPZPbB3opJ",
        "outputId": "56c3ee59-40c5-4fc8-e6b7-b9345b374225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 122])\n"
          ]
        }
      ],
      "source": [
        "print(train_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWxJqiom3opJ"
      },
      "outputs": [],
      "source": [
        "# Generate noisy copies of the training data\n",
        "train_data = []\n",
        "\n",
        "for i in range(num_clusters):\n",
        "    train_clusters = []\n",
        "    seq = train_consensus_strands[i]\n",
        "    for j in range(10):\n",
        "        noisy_seq = sim_error(seq, pi=random.uniform(0.03, 0.09), pd=random.uniform(0.03, 0.09), \n",
        "        ps=random.uniform(0.03, 0.09))\n",
        "        noisy_seq_t = [bmap[c] for c in noisy_seq]\n",
        "#         noisy_seq_t = Variable(torch.FloatTensor([one_hot(c) for c in noisy_seq])).cuda()\n",
        "        train_clusters.append(noisy_seq_t)\n",
        "        \n",
        "    train_data.append(train_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCnttF943opJ",
        "outputId": "afcaf188-9bbe-4bb1-9598-223195b2a8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "145\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        if (len(train_data[i][j]) > max_length):\n",
        "            max_length = len(train_data[i][j])\n",
        "\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaTxuDod3opK",
        "outputId": "b7feb046-d097-4eac-a148-dabb3c05ec97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97\n"
          ]
        }
      ],
      "source": [
        "min_length = 0\n",
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        if (i == 0 and j == 0):\n",
        "            min_length = len(train_data[i][j])\n",
        "            \n",
        "        elif (len(train_data[i][j]) < min_length):\n",
        "            min_length = len(train_data[i][j])\n",
        "\n",
        "print(min_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG8biE8t3opK"
      },
      "outputs": [],
      "source": [
        "for i in range(num_clusters):\n",
        "    for j in range(10):\n",
        "        diff = max_length - len(train_data[i][j])\n",
        "        for k in range(diff):\n",
        "            train_data[i][j].append(int(4))\n",
        "\n",
        "train_data = torch.Tensor(train_data).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0j1sU4S3opK",
        "outputId": "846ab370-3e11-43fd-fa68-ab3a92ff26a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 10, 145])\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp1LoDtL3opL"
      },
      "outputs": [],
      "source": [
        "model = DeepConsensus(num_tokens=7, dim_model=122, num_heads=2, \n",
        "                      num_encoder_layers=6, num_decoder_layers=0, dropout_p=0.1)\n",
        "model.cuda()\n",
        "model.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Loqme5s3opL"
      },
      "outputs": [],
      "source": [
        "initial_lr = 0.1\n",
        "lr=initial_lr\n",
        "optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wtQdhhW3opL",
        "outputId": "27883a5c-bea4-4bfe-bb01-8254c6612a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one-hot encoding for DNA bases\n",
            "A: [[1, 0, 0, 0, 0, 0, 0]]\n",
            "C: [[0, 1, 0, 0, 0, 0, 0]]\n",
            "G: [[0, 0, 1, 0, 0, 0, 0]]\n",
            "T: [[0, 0, 0, 1, 0, 0, 0]]\n",
            "$: [[0, 0, 0, 0, 1, 0, 0]]\n",
            "%: [[0, 0, 0, 0, 0, 1, 0]]\n",
            "#: [[0, 0, 0, 0, 0, 0, 1]]\n"
          ]
        }
      ],
      "source": [
        "def vec_to_one_hot(b):\n",
        "    t = [[0,0,0,0,0,0,0]]\n",
        "    i = b\n",
        "    t[0][i] = 1\n",
        "    return t\n",
        "\n",
        "print(\"one-hot encoding for DNA bases\")\n",
        "print(\"A:\", vec_to_one_hot(0))\n",
        "print(\"C:\", vec_to_one_hot(1))\n",
        "print(\"G:\", vec_to_one_hot(2))\n",
        "print(\"T:\", vec_to_one_hot(3))\n",
        "print(\"$:\", vec_to_one_hot(4))\n",
        "print(\"%:\", vec_to_one_hot(5))\n",
        "print(\"#:\", vec_to_one_hot(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0yGosIY3opL",
        "outputId": "7fa866b9-d5ca-475c-922a-6c9f85149e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 122, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "train_target_one_hot = []\n",
        "\n",
        "for i in range(int(len(train_target))):\n",
        "    train_target_one_hot.append([])\n",
        "    for j in range(int(len(train_target[i]))):\n",
        "        train_target_one_hot[i].append(vec_to_one_hot(int(train_target[i][j])))\n",
        "        \n",
        "train_target_one_hot = torch.Tensor(train_target_one_hot).long().cuda()\n",
        "print(train_target_one_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGY2sayk3opM",
        "outputId": "ee53523f-8780-4cdc-b8d6-286eed30d3be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training loss: 0.0010702887535095215 learning rate: 0.1\n",
            "Epoch: 1 Training loss: 0.0010538521766662598 learning rate: 0.095\n",
            "Epoch: 2 Training loss: 0.0010507613182067872 learning rate: 0.095\n",
            "Epoch: 3 Training loss: 0.00104957857131958 learning rate: 0.09025\n",
            "Epoch: 4 Training loss: 0.0010510922431945801 learning rate: 0.09025\n",
            "Epoch: 5 Training loss: 0.0010519457817077637 learning rate: 0.0857375\n",
            "Epoch: 6 Training loss: 0.0010436738014221192 learning rate: 0.0857375\n",
            "Epoch: 7 Training loss: 0.0010374543190002441 learning rate: 0.08145062499999998\n",
            "Epoch: 8 Training loss: 0.0010440868377685547 learning rate: 0.08145062499999998\n",
            "Epoch: 9 Training loss: 0.0010362844467163086 learning rate: 0.07737809374999999\n",
            "Epoch: 10 Training loss: 0.0010397610664367675 learning rate: 0.07737809374999999\n",
            "Epoch: 11 Training loss: 0.0010401071548461914 learning rate: 0.07350918906249998\n",
            "Epoch: 12 Training loss: 0.0010396754264831542 learning rate: 0.07350918906249998\n",
            "Epoch: 13 Training loss: 0.001036667251586914 learning rate: 0.06983372960937498\n",
            "Epoch: 14 Training loss: 0.0010391613006591797 learning rate: 0.06983372960937498\n",
            "Epoch: 15 Training loss: 0.0010399619102478028 learning rate: 0.06634204312890622\n",
            "Epoch: 16 Training loss: 0.0010449192047119141 learning rate: 0.06634204312890622\n",
            "Epoch: 17 Training loss: 0.001035741138458252 learning rate: 0.0630249409724609\n",
            "Epoch: 18 Training loss: 0.0010321462631225585 learning rate: 0.0630249409724609\n",
            "Epoch: 19 Training loss: 0.0010359260559082031 learning rate: 0.05987369392383786\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "num_epochs = 20\n",
        "\n",
        "range_ = (1, 120)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(int(len(train_data))):\n",
        "        train_loss = 0\n",
        "        s, e = range_\n",
        "        optimizer.zero_grad()\n",
        "        count = 0\n",
        "        for seq in train_data[i]:\n",
        "            model.zero_grad()\n",
        "            count = count + 1\n",
        "            # Noisy clusters (training data)\n",
        "            seq = seq[s-1:e]\n",
        "            seq_ = seq.view(-1,120)\n",
        "            # Original string (training target)\n",
        "            seq_target = train_target[i][s-1:e]\n",
        "            seq_target = seq_target.view(-1, 120)\n",
        "            # Forward Prop\n",
        "            out = model(seq_, seq_target)\n",
        "            # Loss computation\n",
        "            train_loss += criterion(out, train_target_one_hot[i][count])\n",
        "            \n",
        "        # Backward propagation operation\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Epoch:\", epoch, \"Training loss:\", train_loss.cpu().item()/len(train_data), \"learning rate:\", lr)\n",
        "        \n",
        "    # Learning rate decay\n",
        "    if epoch % 2 ==0:\n",
        "        lr *= 0.95\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    \n",
        "if (num_epochs > 0):\n",
        "    torch.save(model.state_dict(), \"deepconsensus_new.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GinidQkT3opM",
        "outputId": "de6b3b5f-49d2-4f61-c8d6-857477455f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"deepconsensus_new.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4Ck_zlV3opM"
      },
      "source": [
        "### Generate Test data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahehqaD03opM",
        "outputId": "5402fb91-3a92-4f14-b004-719adf53280c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%GGAGCACACACACATCTGGTTGTTGATGTCGGGAAAGTCTAGCAGTCGAGCAGCTGTGTTGACGTCTATGGGAGAGTTTTTATGCTTTATTGCACCGATACGCGCCAGAATTCGTCGAAA#\n",
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "# Generate DNA clusters to test model\n",
        "num_test_clusters = 1000\n",
        "test_consensus_strands = []\n",
        "test_target = []\n",
        "\n",
        "for i in range(num_test_clusters):\n",
        "    strand = [\"%\"]\n",
        "    for _ in range(120):\n",
        "        strand.append(random.choice([\"A\",\"C\",\"G\",\"T\"]))\n",
        "    strand.append(\"#\")\n",
        "    \n",
        "    test_consensus_strands.append(strand)\n",
        "    strand_t = [bmap[c] for c in strand]\n",
        "    \n",
        "    test_target.append(strand_t)\n",
        "    \n",
        "print(\"\".join(strand))\n",
        "\n",
        "print(len(test_consensus_strands))\n",
        "print(len(test_target))\n",
        "\n",
        "test_target = torch.Tensor(test_target).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIUMwOQc3opM"
      },
      "outputs": [],
      "source": [
        "# Generate noisy copies of the test data\n",
        "test_data = []\n",
        "\n",
        "for i in range(num_test_clusters):\n",
        "    test_clusters = []\n",
        "    seq = test_consensus_strands[i]\n",
        "    for j in range(10):\n",
        "        noisy_seq = sim_error(seq, pi=0.04, pd=0.04, ps=0.04)\n",
        "        noisy_seq_t = [bmap[c] for c in noisy_seq]\n",
        "        \n",
        "        test_clusters.append(noisy_seq_t)\n",
        "        \n",
        "    test_data.append(test_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGoVOrx03opN",
        "outputId": "9caa5ade-23d6-437b-846d-9e0996562166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "135\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        if (len(test_data[i][j]) > max_length):\n",
        "            max_length = len(test_data[i][j])\n",
        "\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgPSwuDA3opN",
        "outputId": "e164df39-8623-41f4-e061-ddab3633e334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111\n"
          ]
        }
      ],
      "source": [
        "min_length = 0\n",
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        if (i == 0 and j == 0):\n",
        "            min_length = len(test_data[i][j])\n",
        "            \n",
        "        elif (len(test_data[i][j]) < min_length):\n",
        "            min_length = len(test_data[i][j])\n",
        "\n",
        "print(min_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo9OeOSs3opN"
      },
      "outputs": [],
      "source": [
        "for i in range(num_test_clusters):\n",
        "    for j in range(10):\n",
        "        diff = max_length - len(test_data[i][j])\n",
        "        test_data[i][j] = test_data[i][j][:-1]\n",
        "        for k in range(diff):\n",
        "            test_data[i][j].append(int(4))\n",
        "        test_data[i][j].append(int(6))\n",
        "\n",
        "test_data = torch.Tensor(test_data).long().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1VZDMDr3opN",
        "outputId": "b2e03d22-0c46-4d06-f532-24749f329836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 10, 135])\n"
          ]
        }
      ],
      "source": [
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8dHIJnc3opO",
        "outputId": "ed57ffd6-3368-4763-e62e-46f57fd39fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 122])\n"
          ]
        }
      ],
      "source": [
        "print(test_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfhzdF6H3opO",
        "outputId": "6bc9df21-09d8-469d-e7cf-ee8c1389d151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7])\n",
            "torch.float32\n",
            "Vectors for one hot of DNA bases\n",
            "A: 0\n",
            "C: 1\n",
            "G: 2\n",
            "T: 3\n",
            "$: 4\n",
            "T: 5\n",
            "$: 6\n"
          ]
        }
      ],
      "source": [
        "def one_hot_to_vec(one_hot):\n",
        "    one_hot = np.array(one_hot)\n",
        "    vec = np.argmax(one_hot, axis = 0)\n",
        "    return vec\n",
        "\n",
        "vec = torch.zeros(7).cpu()\n",
        "vec[0] = 1\n",
        "print(vec.shape)\n",
        "print(vec.dtype)\n",
        "\n",
        "print(\"Vectors for one hot of DNA bases\")\n",
        "print(\"A:\", one_hot_to_vec(vec))\n",
        "print(\"C:\", one_hot_to_vec([0, 1, 0, 0, 0, 0, 0]))\n",
        "print(\"G:\", one_hot_to_vec([0, 0, 1, 0, 0, 0, 0]))\n",
        "print(\"T:\", one_hot_to_vec([0, 0, 0, 1, 0, 0, 0]))\n",
        "print(\"$:\", one_hot_to_vec([0, 0, 0, 0, 1, 0, 0]))\n",
        "print(\"T:\", one_hot_to_vec([0, 0, 0, 0, 0, 1, 0]))\n",
        "print(\"$:\", one_hot_to_vec([0, 0, 0, 0, 0, 0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STuVm8bM3opO",
        "outputId": "36e387ee-7ba5-4b04-a158-d9475b2983e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 122, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "test_target_one_hot = []\n",
        "\n",
        "for i in range(int(len(test_target))):\n",
        "    test_target_one_hot.append([])\n",
        "    for j in range(int(len(test_target[i]))):\n",
        "        test_target_one_hot[i].append(vec_to_one_hot(int(test_target[i][j])))\n",
        "        \n",
        "test_target_one_hot = torch.Tensor(test_target_one_hot).long().cuda()\n",
        "print(test_target_one_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu15c3dw3opO",
        "outputId": "053e3194-d567-4d16-93b7-ae68427a5305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for forward prop per DNA sequence = 0.007749319076538086 sec\n",
            "Time for accuracy calculation per DNA sequence = 0.009584903717041016 sec\n",
            "Accuracy = 0.9918032786885246\n"
          ]
        }
      ],
      "source": [
        "# Perform Inference on the trained model\n",
        "\n",
        "range_ = (1, 122)\n",
        "accuracy = 0\n",
        "\n",
        "model.eval()\n",
        "# Run again\n",
        "for i in range(len(test_data)):\n",
        "    test_loss = 0\n",
        "    s, e = range_\n",
        "    for seq in test_data[i]:\n",
        "        start_time = time.time()\n",
        "        model.zero_grad()\n",
        "        # Original string (test target)\n",
        "        seq_target = test_target[i][s-1:e]\n",
        "        seq_target = seq_target.view(-1, 122)\n",
        "        # Noisy clusters (test data)\n",
        "        seq = seq[s-1:e]\n",
        "        seq_ = seq.view(-1,122)\n",
        "        out = model(seq_, seq_target)\n",
        "        check_time = time.time()\n",
        "        \n",
        "        for j in range(122):\n",
        "            if (one_hot_to_vec(out[0][j].detach().cpu().numpy()) == \n",
        "                one_hot_to_vec(test_target_one_hot[i][j].reshape(7).detach().cpu().numpy())):\n",
        "                \n",
        "                accuracy = accuracy + 1\n",
        "                \n",
        "        end_time = time.time()\n",
        "        \n",
        "print(\"Time for forward prop per DNA sequence = \" + str(check_time - start_time) + \" sec\")\n",
        "print(\"Time for accuracy calculation per DNA sequence = \" + str(end_time - check_time) + \" sec\")\n",
        "                \n",
        "print(\"Accuracy = \" + str(accuracy/(test_data.shape[0] * test_data.shape[1] * 122)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "deepconsensus-improved.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}